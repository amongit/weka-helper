http://www.zdnet.com/article/google-hacks-the-public-domain-the-right-to-be-forgotten/#ftag=RSSbaffb68
Google hacks the public domain: The rite to be forgotten
Last summer the European Court of Justice recently ruled on the so-called "Right to be Forgotten" granting members of the public limited rights to request that search engines like Google suppress links to personal information under some circumstances. The decision has been roundly criticised by technologists, by American libertarians, and even by some privacy advocates. Objections are raised on various grounds; the one I want to answer here is that search engines should not have to censor "facts" retrieved from the "public domain".
In an address on August 18, the European Union's Justice Commissioner Martine Reicherts made the following points about the Right to be Forgotten (RTBF):
For The New Yorker, Toobin interviewed Kent Walker, Google's general counsel. Walker said Google likes to think of itself as a "card catalogue." "We don't create the information. We make it accessible. A decision like [the ECJ's], which makes us decide what goes inside the card catalogue, forces us into a role we don't want."
But there's a great deal more to search than Walker lets on.
Google certainly does create fresh personal pnformation, and in stupendous quantities. Their search engine is the bedrock of a hundred billion dollar business, founded on a mission to "organize the world's information". Google search is an incredible machine, the result of one of the world's biggest ever and ongoing software R&D projects. Few of us now can imagine life without Internet search and instant access to limitless information that would otherwise be utterly invisible. Search really is magic - just as Arthur C. Clarke said any sufficiently advanced technology would be.
On its face therefore, no search result is a passive reproduction of data from a "public domain". Google makes the public domain public.
But while search is free, it is hyper profitable, for the whole point of it is to underpin a gigantic advertising business. The search engine might not create the raw facts and figures in response to our queries, but it covertly creates and collects symbiotic metadata, complicating the picture. Google monitors our search histories, interests, reactions and habits, as well as details of the devices we're using, when and where and even how we are using them, all in order to divine our deep predilections. These insights are then provided in various ways to Google's paying customers (advertisers) and are also fed back into the search engine, to continuously tune it.
The things we see courtesy of Google are shaped not only by their page ranking metrics but also by the company's knowledge of our preferences (which it forms by watching us across the whole portfolio of search, Gmail, maps, YouTube, and the Google+ social network). When we search for something, Google tries to predict what we really want to know.
In the modern vernacular, Google hacks the public domain.
The collection and monetization of personal metadata is inextricably linked to the machinery of search. The information Google serves up to us is shaped and transformed to such an extent, in the service of Google's business objectives, that it should be regarded as synthetic and therefore the responsibility of the company. Their search algorithms are famously secret, putting them beyond peer review; nevertheless, there is a whole body of academic work now on the subtle and untoward influences that Google exerts as it filters and shapes the version reality it thinks we need to see.
Some objections to the RTBF ruling see it as censorship, or meddling with the "truth". But what exactly is the state of the truth that Google purportedly serves up? Search results are influenced by many arbitrary factors of Google's choosing; we don't know what those factors are, but they are dictated by Google's business interests. So in principle, why is an individual's interests in having some influence over search results any less worthy than Google's? The "right to be forgotten" is an unfortunate misnomer: It is really more of a "limited right to have search results filtered differently."
When people frame RTBF as "rewriting history" they seem to regard Googe's search results as a formal public record. But they're not - they are the means to an end for an advertising business. Search results represent Google's proprietary assessment of what matters. And they are relative. Search results are utterly different from one user to another, and from one month to the next. Why should this customised stream of corporate consciousness not be subject to reasonable editing so as to balance the rights of people that it happens to include?
If Google's machinery reveals personal information that was hitherto impossible to find, then why shouldn't it at least participate in protecting the interests of the people affected? I don't deny that modern technology and hyper-connectivity creates new challenges for the law, and that traditional notions of privacy may be shifting. But it's not a step-change, and in the meantime, we need to tread carefully. There are as many unintended consequences and problems in the new technology as there are in the established laws. The powerful owners or benefactors of these technologies should accept some responsibility for the privacy impacts. With its talents and resources, Google could rise to the challenge of better managing privacy, instead of pleading that it's not their problem.
Resources
The State of Privacy in 2015
Big Privacy Rises to the Challenges of Big Data
